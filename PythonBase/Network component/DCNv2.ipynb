{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 27, 64, 64])\n",
      "torch.Size([2, 32, 64, 64])\n",
      "torch.Size([2, 27, 32, 32])\n",
      "torch.Size([2, 32, 32, 32])\n",
      "torch.Size([2, 27, 32, 32])\n",
      "torch.Size([2, 64, 32, 32])\n",
      "torch.Size([2, 27, 16, 16])\n",
      "torch.Size([2, 64, 16, 16])\n",
      "torch.Size([2, 27, 16, 16])\n",
      "torch.Size([2, 128, 16, 16])\n",
      "torch.Size([2, 27, 8, 8])\n",
      "torch.Size([2, 128, 8, 8])\n",
      "torch.Size([2, 27, 8, 8])\n",
      "torch.Size([2, 256, 8, 8])\n",
      "torch.Size([2, 3, 64, 64])\n",
      "torch.Size([2, 256, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ntorch.Size([2, 3, 64, 64])\\ntorch.Size([2, 256, 4, 4])\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.ops\n",
    "from torch import nn\n",
    "import math\n",
    "\n",
    "\n",
    "class DCNv2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1):\n",
    "\n",
    "        super(DCNv2, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride if type(stride) == tuple else (stride, stride)\n",
    "        self.padding = padding\n",
    "        \n",
    "        # init weight and bias\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "\n",
    "        # offset conv\n",
    "        self.conv_offset_mask = nn.Conv2d(in_channels, \n",
    "                                          3 * kernel_size * kernel_size,\n",
    "                                          kernel_size=kernel_size, \n",
    "                                          stride=stride,\n",
    "                                          padding=self.padding, \n",
    "                                          bias=True)\n",
    "        \n",
    "        # init        \n",
    "        self.reset_parameters()\n",
    "        self._init_weight()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        n = self.in_channels * (self.kernel_size**2)\n",
    "        stdv = 1. / math.sqrt(n)\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        self.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def _init_weight(self):\n",
    "        # init offset_mask conv\n",
    "        nn.init.constant_(self.conv_offset_mask.weight, 0.)\n",
    "        nn.init.constant_(self.conv_offset_mask.bias, 0.)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_offset_mask(x)\n",
    "        print(out.shape)\n",
    "        o1, o2, mask = torch.chunk(out, 3, dim=1)\n",
    "        offset = torch.cat((o1, o2), dim=1)\n",
    "        mask = torch.sigmoid(mask)\n",
    "\n",
    "        x = torchvision.ops.deform_conv2d(input=x, \n",
    "                                          offset=offset, \n",
    "                                          weight=self.weight, \n",
    "                                          bias=self.bias, \n",
    "                                          padding=self.padding,\n",
    "                                          mask=mask,\n",
    "                                          stride=self.stride)\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    DCNv2(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    DCNv2(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "    DCNv2(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    DCNv2(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "    DCNv2(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    DCNv2(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "    DCNv2(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.MaxPool2d(2, 2)\n",
    ")\n",
    "x = torch.randn(2, 3, 64, 64)\n",
    "y = model(x)\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "\"\"\"\n",
    "torch.Size([2, 3, 64, 64])\n",
    "torch.Size([2, 256, 4, 4])\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
