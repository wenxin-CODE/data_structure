{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/weixin_43143670/article/details/104791946"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将标记图（每个像素值代该位置像素点的类别）转换为onehot编码\n",
    "def onehot(data, n):\n",
    "    buf = np.zeros(data.shape + (n, ))\n",
    "    nmsk = np.arange(data.size)*n + data.ravel()\n",
    "    buf.ravel()[nmsk-1] = 1\n",
    "    return buf\n",
    "\n",
    "# 利用torchvision提供的transform，定义原始图片的预处理步骤（转换为tensor和标准化处理） \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# 利用torch提供的Dataset类，定义我们自己的数据集\n",
    "class BagDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(os.listdir('D:\\\\python\\\\CV&NLP\\\\pytorch-FCN-easiest-demo/bag_data'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.listdir('D:\\\\python\\\\CV&NLP\\\\pytorch-FCN-easiest-demo/bag_data')[idx]\n",
    "        imgA = cv2.imread('D:\\\\python\\\\CV&NLP\\\\pytorch-FCN-easiest-demo/bag_data/'+img_name)\n",
    "        imgA = cv2.resize(imgA, (160, 160))\n",
    "        imgB = cv2.imread('D:\\\\python\\\\CV&NLP\\\\pytorch-FCN-easiest-demo/bag_data_msk/'+img_name, 0)\n",
    "        imgB = cv2.resize(imgB, (160, 160))\n",
    "        imgB = imgB/255\n",
    "        imgB = imgB.astype('uint8')\n",
    "        imgB = onehot(imgB, 2)\n",
    "        imgB = imgB.transpose(2,0,1)\n",
    "        imgB = torch.FloatTensor(imgB)\n",
    "        #print(imgB.shape)\n",
    "        if self.transform:\n",
    "            imgA = self.transform(imgA)    \n",
    "\n",
    "        return imgA, imgB\n",
    "\n",
    "# 实例化数据集\n",
    "bag = BagDataset(transform)\n",
    "\n",
    "train_size = int(0.9 * len(bag))\n",
    "test_size = len(bag) - train_size\n",
    "train_dataset, test_dataset = random_split(bag, [train_size, test_size])\n",
    "\n",
    "# 利用DataLoader生成一个分batch获取数据的可迭代对象\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <-------------------------------------------------------->#\n",
    "# 下面开始定义网络模型\n",
    "# 先定义VGG结构\n",
    "\n",
    "# ranges 是用于方便获取和记录每个池化层得到的特征图\n",
    "# 例如vgg16，需要(0, 5)的原因是为方便记录第一个pooling层得到的输出(详见下午、稳VGG定义)\n",
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# Vgg网络结构配置（数字代表经过卷积后的channel数，‘M’代表卷积层）\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "# 由cfg构建vgg-Net的卷积层和池化层(block1-block5)\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# 下面开始构建VGGnet\n",
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained = True, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "        \n",
    "        # 获取VGG模型训练好的参数，并加载（第一次执行需要下载一段时间）\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # 去掉vgg最后的全连接层(classifier)\n",
    "        if remove_fc:  \n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "        # 利用之前定义的ranges获取每个maxpooling层输出的特征图\n",
    "        for idx, (begin, end) in enumerate(self.ranges):\n",
    "        #self.ranges = ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)) (vgg16 examples)\n",
    "            for layer in range(begin, end):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "        # output 为一个字典键x1d对应第一个maxpooling输出的特征图，x2...x5类推\n",
    "        return output\n",
    "\n",
    "# 下面由VGG构建FCN8s\n",
    "class FCN8s(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=1, stride=1, padding=0, dilation=1)\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']    # maxpooling5的feature map (1/32)\n",
    "        x4 = output['x4']    # maxpooling4的feature map (1/16)\n",
    "        x3 = output['x3']    # maxpooling3的feature map (1/8)\n",
    "    \n",
    "        score = self.relu(self.conv6(x5))    # conv6  size不变 (1/32)\n",
    "        score = self.relu(self.conv7(score)) # conv7  size不变 (1/32)\n",
    "        score = self.relu(self.deconv1(x5))   # out_size = 2*in_size (1/16)       \n",
    "        score = self.bn1(score + x4)                      \n",
    "        score = self.relu(self.deconv2(score)) # out_size = 2*in_size (1/8)           \n",
    "        score = self.bn2(score + x3)                      \n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  # out_size = 2*in_size (1/4)\n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  # out_size = 2*in_size (1/2)\n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  # out_size = 2*in_size (1)\n",
    "        score = self.classifier(score)                    # size不变，使输出的channel等于类别数\n",
    "\n",
    "        return score  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\d2l\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\anaconda\\envs\\d2l\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.0.weight torch.Size([64, 3, 3, 3])\n",
      "features.0.bias torch.Size([64])\n",
      "features.2.weight torch.Size([64, 64, 3, 3])\n",
      "features.2.bias torch.Size([64])\n",
      "features.5.weight torch.Size([128, 64, 3, 3])\n",
      "features.5.bias torch.Size([128])\n",
      "features.7.weight torch.Size([128, 128, 3, 3])\n",
      "features.7.bias torch.Size([128])\n",
      "features.10.weight torch.Size([256, 128, 3, 3])\n",
      "features.10.bias torch.Size([256])\n",
      "features.12.weight torch.Size([256, 256, 3, 3])\n",
      "features.12.bias torch.Size([256])\n",
      "features.14.weight torch.Size([256, 256, 3, 3])\n",
      "features.14.bias torch.Size([256])\n",
      "features.17.weight torch.Size([512, 256, 3, 3])\n",
      "features.17.bias torch.Size([512])\n",
      "features.19.weight torch.Size([512, 512, 3, 3])\n",
      "features.19.bias torch.Size([512])\n",
      "features.21.weight torch.Size([512, 512, 3, 3])\n",
      "features.21.bias torch.Size([512])\n",
      "features.24.weight torch.Size([512, 512, 3, 3])\n",
      "features.24.bias torch.Size([512])\n",
      "features.26.weight torch.Size([512, 512, 3, 3])\n",
      "features.26.bias torch.Size([512])\n",
      "features.28.weight torch.Size([512, 512, 3, 3])\n",
      "features.28.bias torch.Size([512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 21944, 20408, 8044, 9912) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\multiprocessing\\queues.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12616\\1697526742.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepo_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_vgg_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12616\\1697526742.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epo_num, show_vgg_params)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mfcn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbag_msk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m             \u001b[1;31m# bag.shape is torch.Size([4, 3, 160, 160])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# bag_msk.shape is torch.Size([4, 2, 160, 160])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1323\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1325\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1326\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\anaconda\\envs\\d2l\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 21944, 20408, 8044, 9912) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# <---------------------------------------------->\n",
    "# 下面开始训练网络\n",
    "\n",
    "# 在训练网络前定义函数用于计算Acc 和 mIou\n",
    "# 计算混淆矩阵\n",
    "def _fast_hist(label_true, label_pred, n_class):\n",
    "    mask = (label_true >= 0) & (label_true < n_class)\n",
    "    hist = np.bincount(\n",
    "        n_class * label_true[mask].astype(int) +\n",
    "        label_pred[mask], minlength=n_class ** 2).reshape(n_class, n_class)\n",
    "    return hist\n",
    "\n",
    " # 根据混淆矩阵计算Acc和mIou\n",
    "def label_accuracy_score(label_trues, label_preds, n_class):\n",
    "    \"\"\"Returns accuracy score evaluation result.\n",
    "      - overall accuracy\n",
    "      - mean accuracy\n",
    "      - mean IU\n",
    "    \"\"\"\n",
    "    hist = np.zeros((n_class, n_class))\n",
    "    for lt, lp in zip(label_trues, label_preds):\n",
    "        hist += _fast_hist(lt.flatten(), lp.flatten(), n_class)\n",
    "    acc = np.diag(hist).sum() / hist.sum()\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_cls = np.diag(hist) / hist.sum(axis=1)\n",
    "    acc_cls = np.nanmean(acc_cls)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        iu = np.diag(hist) / (\n",
    "            hist.sum(axis=1) + hist.sum(axis=0) - np.diag(hist)\n",
    "        )\n",
    "    mean_iu = np.nanmean(iu)\n",
    "    freq = hist.sum(axis=1) / hist.sum()\n",
    "    return acc, acc_cls, mean_iu\n",
    "    \n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(epo_num=50, show_vgg_params=False):\n",
    "\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    vgg_model = VGGNet(requires_grad=True, show_params=show_vgg_params)\n",
    "    fcn_model = FCN8s(pretrained_net=vgg_model, n_class=2)\n",
    "    fcn_model = fcn_model.to(device)\n",
    "    # 这里只有两类，采用二分类常用的损失函数BCE\n",
    "    criterion = nn.BCELoss().to(device)     \n",
    "    # 随机梯度下降优化，学习率0.001，惯性分数0.7\n",
    "    optimizer = optim.SGD(fcn_model.parameters(), lr=1e-3, momentum=0.7)\n",
    "    \n",
    "    # 记录训练过程相关指标\n",
    "    all_train_iter_loss = []\n",
    "    all_test_iter_loss = []\n",
    "    test_Acc = []\n",
    "    test_mIou = []\n",
    "    # start timing\n",
    "    prev_time = datetime.now()\n",
    "\n",
    "    for epo in range(epo_num):\n",
    "        \n",
    "        # 训练\n",
    "        train_loss = 0\n",
    "        fcn_model.train()\n",
    "        for index, (bag, bag_msk) in enumerate(train_dataloader):\n",
    "            # bag.shape is torch.Size([4, 3, 160, 160])\n",
    "            # bag_msk.shape is torch.Size([4, 2, 160, 160])\n",
    "\n",
    "            bag = bag.to(device)\n",
    "            bag_msk = bag_msk.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = fcn_model(bag)\n",
    "            output = torch.sigmoid(output) # output.shape is torch.Size([4, 2, 160, 160])\n",
    "            loss = criterion(output, bag_msk)\n",
    "            loss.backward()     # 需要计算导数，则调用backward\n",
    "            iter_loss = loss.item()    # .item()返回一个具体的值，一般用于loss和acc\n",
    "            all_train_iter_loss.append(iter_loss)\n",
    "            train_loss += iter_loss\n",
    "            optimizer.step()\n",
    "\n",
    "            output_np = output.cpu().detach().numpy().copy() \n",
    "            output_np = np.argmin(output_np, axis=1)\n",
    "            bag_msk_np = bag_msk.cpu().detach().numpy().copy() \n",
    "            bag_msk_np = np.argmin(bag_msk_np, axis=1)\n",
    "            \n",
    "            # 每15个bacth，输出一次训练过程的数据\n",
    "            if np.mod(index, 15) == 0:\n",
    "                print('epoch {}, {}/{},train loss is {}'.format(epo, index, len(train_dataloader), iter_loss))\n",
    "\n",
    "        # 验证\n",
    "        test_loss = 0\n",
    "        fcn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for index, (bag, bag_msk) in enumerate(test_dataloader):\n",
    "\n",
    "                bag = bag.to(device)\n",
    "                bag_msk = bag_msk.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = fcn_model(bag)\n",
    "                output = torch.sigmoid(output) # output.shape is torch.Size([4, 2, 160, 160])\n",
    "                loss = criterion(output, bag_msk)\n",
    "                iter_loss = loss.item()\n",
    "                all_test_iter_loss.append(iter_loss)\n",
    "                test_loss += iter_loss\n",
    "\n",
    "                output_np = output.cpu().detach().numpy().copy() \n",
    "                output_np = np.argmin(output_np, axis=1)\n",
    "                bag_msk_np = bag_msk.cpu().detach().numpy().copy() \n",
    "                bag_msk_np = np.argmin(bag_msk_np, axis=1)\n",
    "                \n",
    "\n",
    "\n",
    "        cur_time = datetime.now()\n",
    "        h, remainder = divmod((cur_time - prev_time).seconds, 3600)\n",
    "        m, s = divmod(remainder, 60)\n",
    "        time_str = \"Time %02d:%02d:%02d\" % (h, m, s)\n",
    "        prev_time = cur_time\n",
    "        \n",
    "        print('<---------------------------------------------------->')\n",
    "        print('epoch: %f'%epo)\n",
    "        print('epoch train loss = %f, epoch test loss = %f, %s'\n",
    "                %( train_loss/len(train_dataloader), test_loss/len(test_dataloader), time_str))\n",
    "        \n",
    "        acc, acc_cls, mean_iu = label_accuracy_score(bag_msk_np, output_np, 2)\n",
    "        test_Acc.append(acc)\n",
    "        test_mIou.append(mIou)\n",
    "\n",
    "        print('Acc = %f, mIou = %f'%(acc, me))\n",
    "        # 每5个epoch存储一次模型\n",
    "        if np.mod(epo, 5) == 0:\n",
    "            # 只存储模型参数\n",
    "            torch.save(fcn_model.state_dict(), 'checkpoints/fcn_model_{}.pth'.format(epo))\n",
    "            print('saveing checkpoints/fcn_model_{}.pth'.format(epo))\n",
    "    # 绘制训练过程数据\n",
    "    plt.figure()\n",
    "    plt.subplot(221)\n",
    "    plt.title('train_loss')\n",
    "    plt.plot(all_train_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(222)\n",
    "    plt.title('test_loss')\n",
    "    plt.plot( all_test_iter_loss)\n",
    "    plt.xlabel('batch')\n",
    "    plt.subplot(223)\n",
    "    plt.title('test_Acc')\n",
    "    plt.plot(test_Acc)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.subplot(224)\n",
    "    plt.title('test_mIou')\n",
    "    plt.plot(test_mIou)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train(epo_num=100, show_vgg_params=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
